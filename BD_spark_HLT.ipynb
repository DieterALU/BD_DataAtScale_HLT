{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bridge.jpg\" alt=\"concrete\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. These ingredients include cement, blast furnace slag, fly ash, \n",
    "water, superplasticizer, coarse aggregate, and fine aggregate. You will use these data to predict the compresive strength of a concrete block. The actual concrete compressive strength (MPa) for a given mixture  - our training  data was determined in a laboratory.   Data from [here](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength)\n",
    "  \n",
    "We now want to be able to predict concrete compressive strength without needing to measure it in a lab. You will need to read the data into spark, clean it by removing some missing values, and prepare it for model fitting. You will then need to fit an appropriate machine learning model, and output your predictions and saved model.  \n",
    "  \n",
    "You can find the data in the file **concrete.csv**. Once you have built your best model with these data. Please make predictions on these new data **concrete_unmeasured.csv** for which we do not know the concrete compressive strength.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start spark app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark_ml\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"concrete.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nas\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cement_kgm3: string (nullable = true)\n",
      " |-- Blast_Furnace_Slag_kgm3: string (nullable = true)\n",
      " |-- Fly_Ash_kgm3: string (nullable = true)\n",
      " |-- Water_kgm3: string (nullable = true)\n",
      " |-- Superplasticizer_kgm3: string (nullable = true)\n",
      " |-- Coarse_Aggregate_kgm3: string (nullable = true)\n",
      " |-- Fine_Aggregate_kgm3: string (nullable = true)\n",
      " |-- Age_days: string (nullable = true)\n",
      " |-- Concrete_compressive_strength_MPa: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to numeric types\n",
    "#import double type from spark sql\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "#convert all columns\n",
    "for col_name in data.columns:\n",
    "    data = data.withColumn(col_name, data[col_name].cast(DoubleType()))\n",
    "    \n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cement_kgm3: double (nullable = true)\n",
      " |-- Blast_Furnace_Slag_kgm3: double (nullable = true)\n",
      " |-- Fly_Ash_kgm3: double (nullable = true)\n",
      " |-- Water_kgm3: double (nullable = true)\n",
      " |-- Superplasticizer_kgm3: double (nullable = true)\n",
      " |-- Coarse_Aggregate_kgm3: double (nullable = true)\n",
      " |-- Fine_Aggregate_kgm3: double (nullable = true)\n",
      " |-- Age_days: double (nullable = true)\n",
      " |-- Concrete_compressive_strength_MPa: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble variables to one feature column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = [\"Cement_kgm3\",\"Blast_Furnace_Slag_kgm3\",\"Fly_Ash_kgm3\",\"Water_kgm3\",\"Superplasticizer_kgm3\",\"Coarse_Aggregate_kgm3\",\"Fine_Aggregate_kgm3\",\"Age_days\"],\n",
    "    outputCol = \"features\")\n",
    "\n",
    "#define the estimator - decision tree\n",
    "dt = DecisionTreeRegressor(labelCol=\"Concrete_compressive_strength_MPa\", featuresCol=\"features\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit pipeline and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the pipeline\n",
    "PipelineModel = pipeline.fit(trainingData)\n",
    "\n",
    "# transform using the pipeline\n",
    "predictions = PipelineModel.transform(testData)\n",
    "\n",
    "# evaluate model fit\n",
    "predictions.select(\"prediction\", \"Concrete_compressive_strength_MPa\")\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Concrete_compressive_strength_MPa\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+------------+----------+---------------------+---------------------+-------------------+--------+---------------------------------+--------------------+------------------+\n",
      "|Cement_kgm3|Blast_Furnace_Slag_kgm3|Fly_Ash_kgm3|Water_kgm3|Superplasticizer_kgm3|Coarse_Aggregate_kgm3|Fine_Aggregate_kgm3|Age_days|Concrete_compressive_strength_MPa|            features|        prediction|\n",
      "+-----------+-----------------------+------------+----------+---------------------+---------------------+-------------------+--------+---------------------------------+--------------------+------------------+\n",
      "|      102.0|                  153.0|         0.0|     192.0|                  0.0|                887.0|              942.0|    90.0|                     25.460969728|[102.0,153.0,0.0,...| 34.73952405039999|\n",
      "|      108.3|                  162.4|         0.0|     203.5|                  0.0|                938.2|              849.0|     3.0|                      2.331807832|[108.3,162.4,0.0,...|       7.594061033|\n",
      "|      108.3|                  162.4|         0.0|     203.5|                  0.0|                938.2|              849.0|     7.0|                      7.723510152|[108.3,162.4,0.0,...|       7.594061033|\n",
      "|      116.0|                  173.0|         0.0|     192.0|                  0.0|                909.8|              891.9|     7.0|                     10.089791784|[116.0,173.0,0.0,...|       7.594061033|\n",
      "|      133.0|                  200.0|         0.0|     192.0|                  0.0|                927.4|              839.2|     3.0|                      6.883728384|[133.0,200.0,0.0,...|       7.594061033|\n",
      "|      135.7|                  203.5|         0.0|     185.7|                  0.0|               1076.2|              759.3|    28.0|                      18.19871902|[135.7,203.5,0.0,...|27.928882541614037|\n",
      "|      136.4|                  161.6|       125.8|     171.6|                 10.4|                922.6|              764.4|    28.0|                     29.073134492|[136.4,161.6,125....|27.928882541614037|\n",
      "|      139.6|                  209.4|         0.0|     192.0|                  0.0|               1047.0|              806.9|     7.0|                      14.58931216|[139.6,209.4,0.0,...|       7.594061033|\n",
      "|      141.3|                  212.0|         0.0|     203.5|                  0.0|                971.8|              748.5|    90.0|                       39.6621069|[141.3,212.0,0.0,...|51.516977622533055|\n",
      "|      141.9|                  166.6|       129.7|     173.5|                 10.9|                882.6|              785.3|    28.0|                     44.611855104|[141.9,166.6,129....|27.928882541614037|\n",
      "|      143.6|                    0.0|       174.9|     158.4|                 17.9|                942.7|              844.5|    28.0|                      15.42357812|[143.6,0.0,174.9,...|    13.09077916625|\n",
      "|      144.0|                    0.0|       175.0|     158.0|                 18.0|                943.0|              844.0|    28.0|                      15.41668336|[144.0,0.0,175.0,...|    13.09077916625|\n",
      "|      144.0|                   15.0|       195.0|     176.0|                  6.0|               1021.0|              709.0|    28.0|                        15.340841|[144.0,15.0,195.0...|27.928882541614037|\n",
      "|      144.8|                    0.0|       133.6|     180.8|                 11.1|                979.5|              811.5|    28.0|                     13.202086448|[144.8,0.0,133.6,...|    13.09077916625|\n",
      "|      145.4|                    0.0|       178.9|     201.7|                  7.8|                824.0|              868.7|    28.0|                     10.535882756|[145.4,0.0,178.9,...|    13.09077916625|\n",
      "|      146.0|                  173.0|         0.0|     182.0|                  3.0|                986.0|              817.0|    28.0|                      23.73865868|[146.0,173.0,0.0,...|27.928882541614037|\n",
      "|      147.8|                  175.1|         0.0|     171.2|                  2.2|               1000.0|              828.5|    28.0|                     26.922658848|[147.8,175.1,0.0,...|27.928882541614037|\n",
      "|      149.0|                  117.6|        91.7|     182.9|                  7.1|                953.4|              780.3|    28.0|                     23.524231644|[149.0,117.6,91.7...|27.928882541614037|\n",
      "|      149.0|                  153.0|       194.0|     192.0|                  8.0|                935.0|              623.0|    28.0|                       24.5798194|[149.0,153.0,194....|27.928882541614037|\n",
      "|      150.0|                  237.0|         0.0|     174.0|                 12.0|               1069.0|              675.0|    28.0|                      37.43165204|[150.0,237.0,0.0,...|27.928882541614037|\n",
      "+-----------+-----------------------+------------+----------+---------------------+---------------------+-------------------+--------+---------------------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.905620863232362\n"
     ]
    }
   ],
   "source": [
    "##Root mean square error\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fitted pipeline for later use\n",
    "PipelineModel.save(\"my_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sure from here on out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = spark.read.csv(\"concrete_unmeasured.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nas\n",
    "data_pred = data_pred.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert to numeric types\n",
    "#import double type from spark sql\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "#convert all columns\n",
    "for col_name in data_pred.columns:\n",
    "    data_pred = data_pred.withColumn(col_name, data_pred[col_name].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
